{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAAonEN+PJJJ46Rn5l8mj0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geethasinghekavini/-NextJS-Project/blob/main/ColomboStockExchange.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "BASE = \"https://www.cse.lk/api/\"\n",
        "CSV_OUT = f\"cse_company_info_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "LETTERS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "\n",
        "SESSION = requests.Session()\n",
        "SESSION.headers.update({\n",
        "    \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
        "    \"User-Agent\": \"Mozilla/5.0\",\n",
        "    \"Origin\": \"https://www.cse.lk\",\n",
        "    \"Referer\": \"https://www.cse.lk/\",\n",
        "})\n",
        "\n",
        "SYMBOL_KEYS = (\"symbol\", \"Symbol\", \"symbolCode\", \"tradingCode\", \"ticker\")\n",
        "\n",
        "def extract_symbols(obj):\n",
        "    \"\"\"\n",
        "    Extract symbols from either:\n",
        "      - a list of dicts/strings\n",
        "      - a dict that *contains* such a list under some key (e.g., 'data', 'content', etc.)\n",
        "    \"\"\"\n",
        "    symbols = set()\n",
        "\n",
        "    def from_list(lst):\n",
        "        for item in lst:\n",
        "            if isinstance(item, dict):\n",
        "                for k in SYMBOL_KEYS:\n",
        "                    if k in item and item[k]:\n",
        "                        symbols.add(str(item[k]))\n",
        "                        break\n",
        "            elif isinstance(item, str):\n",
        "                # Some APIs return pure symbol strings\n",
        "                symbols.add(item)\n",
        "\n",
        "    if isinstance(obj, list):\n",
        "        from_list(obj)\n",
        "    elif isinstance(obj, dict):\n",
        "        # If itâ€™s a dict, search for the first list-like value(s)\n",
        "        for v in obj.values():\n",
        "            if isinstance(v, list):\n",
        "                from_list(v)\n",
        "            elif isinstance(v, dict):\n",
        "                # nested dicts may contain lists too\n",
        "                for vv in v.values():\n",
        "                    if isinstance(vv, list):\n",
        "                        from_list(vv)\n",
        "\n",
        "    return sorted(symbols)\n",
        "\n",
        "def get_symbols(letter):\n",
        "    r = SESSION.post(BASE + \"alphabetical\", data={\"alphabet\": letter})\n",
        "    if r.status_code != 200:\n",
        "        print(f\"[{letter}] HTTP {r.status_code}\")\n",
        "        return []\n",
        "    try:\n",
        "        data = r.json()\n",
        "    except Exception as e:\n",
        "        print(f\"[{letter}] JSON error: {e}\")\n",
        "        return []\n",
        "\n",
        "    syms = extract_symbols(data)\n",
        "    if not syms:\n",
        "        # Debug hint: show the top-level keys so you can see the shape\n",
        "        if isinstance(data, dict):\n",
        "            print(f\"[{letter}] No symbols found. Top-level keys: {list(data.keys())}\")\n",
        "        else:\n",
        "            print(f\"[{letter}] No symbols found. Type: {type(data).__name__}\")\n",
        "    return syms\n",
        "\n",
        "def get_company_info(symbol):\n",
        "    r = SESSION.post(BASE + \"companyInfoSummery\", data={\"symbol\": symbol})\n",
        "    if r.status_code != 200:\n",
        "        print(f\"{symbol}: HTTP {r.status_code}\")\n",
        "        return None\n",
        "    try:\n",
        "        data = r.json()\n",
        "        if not isinstance(data, dict):\n",
        "            data = {\"raw\": data}\n",
        "        data.setdefault(\"symbol\", symbol)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"{symbol}: JSON error {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    # 1) gather symbols Aâ€“Z\n",
        "    all_symbols = []\n",
        "    for L in LETTERS:\n",
        "        syms = get_symbols(L)\n",
        "        print(f\"{L}: {len(syms)} symbols\")\n",
        "        all_symbols.extend(syms)\n",
        "    all_symbols = sorted(set(all_symbols))\n",
        "    print(f\"Total unique symbols: {len(all_symbols)}\")\n",
        "\n",
        "    # 2) fetch company info\n",
        "    rows, keys = [], set()\n",
        "    for sym in all_symbols:\n",
        "        info = get_company_info(sym)\n",
        "        if info:\n",
        "            rows.append(info)\n",
        "            keys.update(info.keys())\n",
        "\n",
        "    if not rows:\n",
        "        print(\"No data fetched.\")\n",
        "        return\n",
        "\n",
        "    # 3) write CSV\n",
        "    fieldnames = [\"symbol\"] + sorted(k for k in keys if k != \"symbol\")\n",
        "    with open(CSV_OUT, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=fieldnames, extrasaction=\"ignore\")\n",
        "        w.writeheader()\n",
        "        for row in rows:\n",
        "            w.writerow(row)\n",
        "\n",
        "    print(f\"Wrote {len(rows)} rows â†’ {CSV_OUT}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Bf2WqXmCP8",
        "outputId": "a0812d4e-e318-4378-e59c-20ac5fbbb864"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: 32 symbols\n",
            "B: 14 symbols\n",
            "C: 48 symbols\n",
            "D: 10 symbols\n",
            "E: 10 symbols\n",
            "F: 2 symbols\n",
            "G: 4 symbols\n",
            "H: 25 symbols\n",
            "I: 1 symbols\n",
            "J: 7 symbols\n",
            "K: 11 symbols\n",
            "L: 27 symbols\n",
            "M: 15 symbols\n",
            "N: 7 symbols\n",
            "O: 4 symbols\n",
            "P: 11 symbols\n",
            "[Q] No symbols found. Top-level keys: ['reqAlphabetical']\n",
            "Q: 0 symbols\n",
            "R: 16 symbols\n",
            "S: 31 symbols\n",
            "T: 19 symbols\n",
            "U: 6 symbols\n",
            "V: 5 symbols\n",
            "W: 3 symbols\n",
            "[X] No symbols found. Top-level keys: ['reqAlphabetical']\n",
            "X: 0 symbols\n",
            "Y: 1 symbols\n",
            "[Z] No symbols found. Top-level keys: ['reqAlphabetical']\n",
            "Z: 0 symbols\n",
            "Total unique symbols: 309\n",
            "Wrote 309 rows â†’ cse_company_info_20250903_043140.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "# OPTIONAL: write an .xlsx alongside the CSV if pandas is available\n",
        "try:\n",
        "    import pandas as pd\n",
        "    PANDAS_OK = True\n",
        "except Exception:\n",
        "    PANDAS_OK = False\n",
        "\n",
        "BASE = \"https://www.cse.lk/api/\"\n",
        "CSV_OUT = f\"cse_company_info_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "XLSX_OUT = CSV_OUT.replace(\".csv\", \".xlsx\")\n",
        "LETTERS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "\n",
        "SESSION = requests.Session()\n",
        "SESSION.headers.update({\n",
        "    \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
        "    \"User-Agent\": \"Mozilla/5.0\",\n",
        "    \"Origin\": \"https://www.cse.lk\",\n",
        "    \"Referer\": \"https://www.cse.lk/\",\n",
        "})\n",
        "\n",
        "SYMBOL_KEYS = (\"symbol\", \"Symbol\", \"symbolCode\", \"tradingCode\", \"ticker\")\n",
        "\n",
        "\n",
        "def flatten(obj, parent_key=\"\", sep=\".\"):\n",
        "    \"\"\"\n",
        "    Flatten nested dict/list structures to a single dict of scalar values.\n",
        "    - dicts -> key paths joined by `sep`\n",
        "    - lists -> indexed keys like key.0, key.1, ...\n",
        "    Scalars pass through unchanged.\n",
        "    \"\"\"\n",
        "    items = []\n",
        "    if isinstance(obj, dict):\n",
        "        for k, v in obj.items():\n",
        "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else str(k)\n",
        "            items.extend(flatten(v, new_key, sep=sep).items())\n",
        "    elif isinstance(obj, list):\n",
        "        for i, v in enumerate(obj):\n",
        "            new_key = f\"{parent_key}{sep}{i}\" if parent_key else str(i)\n",
        "            items.extend(flatten(v, new_key, sep=sep).items())\n",
        "    else:\n",
        "        items.append((parent_key if parent_key else \"value\", obj))\n",
        "    return dict(items)\n",
        "\n",
        "\n",
        "def extract_symbols(obj):\n",
        "    \"\"\"\n",
        "    Extract symbols from either:\n",
        "      - a list of dicts/strings\n",
        "      - a dict that *contains* such a list under some key (e.g., 'data', 'content', etc.)\n",
        "    \"\"\"\n",
        "    symbols = set()\n",
        "\n",
        "    def from_list(lst):\n",
        "        for item in lst:\n",
        "            if isinstance(item, dict):\n",
        "                for k in SYMBOL_KEYS:\n",
        "                    if k in item and item[k]:\n",
        "                        symbols.add(str(item[k]))\n",
        "                        break\n",
        "            elif isinstance(item, str):\n",
        "                symbols.add(item)\n",
        "\n",
        "    if isinstance(obj, list):\n",
        "        from_list(obj)\n",
        "    elif isinstance(obj, dict):\n",
        "        for v in obj.values():\n",
        "            if isinstance(v, list):\n",
        "                from_list(v)\n",
        "            elif isinstance(v, dict):\n",
        "                for vv in v.values():\n",
        "                    if isinstance(vv, list):\n",
        "                        from_list(vv)\n",
        "\n",
        "    return sorted(symbols)\n",
        "\n",
        "\n",
        "def get_symbols(letter):\n",
        "    r = SESSION.post(BASE + \"alphabetical\", data={\"alphabet\": letter})\n",
        "    if r.status_code != 200:\n",
        "        print(f\"[{letter}] HTTP {r.status_code}\")\n",
        "        return []\n",
        "    try:\n",
        "        data = r.json()\n",
        "    except Exception as e:\n",
        "        print(f\"[{letter}] JSON error: {e}\")\n",
        "        return []\n",
        "\n",
        "    syms = extract_symbols(data)\n",
        "    if not syms:\n",
        "        if isinstance(data, dict):\n",
        "            print(f\"[{letter}] No symbols found. Top-level keys: {list(data.keys())}\")\n",
        "        else:\n",
        "            print(f\"[{letter}] No symbols found. Type: {type(data).__name__}\")\n",
        "    return syms\n",
        "\n",
        "\n",
        "def get_company_info(symbol):\n",
        "    r = SESSION.post(BASE + \"companyInfoSummery\", data={\"symbol\": symbol})\n",
        "    if r.status_code != 200:\n",
        "        print(f\"{symbol}: HTTP {r.status_code}\")\n",
        "        return None\n",
        "    try:\n",
        "        data = r.json()\n",
        "        if not isinstance(data, dict):\n",
        "            data = {\"raw\": data}\n",
        "        # guarantee symbol and a friendly name field exist\n",
        "        data.setdefault(\"symbol\", symbol)\n",
        "        # some payloads may use different keys for name; try to unify\n",
        "        if \"name\" not in data:\n",
        "            for k in (\"companyName\", \"CompanyName\", \"Name\"):\n",
        "                if k in data:\n",
        "                    data[\"name\"] = data[k]\n",
        "                    break\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"{symbol}: JSON error {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 1) gather symbols Aâ€“Z\n",
        "    all_symbols = []\n",
        "    for L in LETTERS:\n",
        "        syms = get_symbols(L)\n",
        "        print(f\"{L}: {len(syms)} symbols\")\n",
        "        all_symbols.extend(syms)\n",
        "    all_symbols = sorted(set(all_symbols))\n",
        "    print(f\"Total unique symbols: {len(all_symbols)}\")\n",
        "\n",
        "    # 2) fetch + flatten company info\n",
        "    flat_rows = []\n",
        "    for idx, sym in enumerate(all_symbols, 1):\n",
        "        info = get_company_info(sym)\n",
        "        if not info:\n",
        "            continue\n",
        "        flat = flatten(info)  # <â€” ensures no JSON blobs end up in a single cell\n",
        "        # keep simple top-level 'symbol' & 'name' too (nice for Excel filters)\n",
        "        flat.setdefault(\"symbol\", info.get(\"symbol\"))\n",
        "        flat.setdefault(\"name\", info.get(\"name\"))\n",
        "        flat_rows.append(flat)\n",
        "\n",
        "        # progress line with name if available\n",
        "        print(f\"[{idx}/{len(all_symbols)}] {sym}  {info.get('name','')}\")\n",
        "\n",
        "    if not flat_rows:\n",
        "        print(\"No data fetched.\")\n",
        "        return\n",
        "\n",
        "    # 3) make a stable header across all rows\n",
        "    all_keys = set()\n",
        "    for r in flat_rows:\n",
        "        all_keys.update(r.keys())\n",
        "    # put the most useful columns first\n",
        "    preferred = [k for k in (\"symbol\", \"name\", \"lastTradedPrice\", \"closingPrice\",\n",
        "                             \"marketCap\", \"turnover\", \"tdyTurnover\", \"tdyShareVolume\")\n",
        "                 if k in all_keys]\n",
        "    other_cols = sorted(k for k in all_keys if k not in preferred)\n",
        "    fieldnames = preferred + other_cols\n",
        "\n",
        "    # 4) write CSV\n",
        "    with open(CSV_OUT, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=fieldnames, extrasaction=\"ignore\")\n",
        "        w.writeheader()\n",
        "        for row in flat_rows:\n",
        "            w.writerow(row)\n",
        "    print(f\" Wrote {len(flat_rows)} rows â†’ {CSV_OUT}\")\n",
        "\n",
        "    # 5) optional: write XLSX if pandas is available\n",
        "    if PANDAS_OK:\n",
        "        df = pd.DataFrame(flat_rows, columns=fieldnames)\n",
        "        df.to_excel(XLSX_OUT, index=False)\n",
        "        print(f\" Also wrote Excel file â†’ {XLSX_OUT}\")\n",
        "    else:\n",
        "        print(\" pandas not installed â€” skipped .xlsx export (CSV is ready).\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PTNPBoq54HO",
        "outputId": "ea62fdbc-64a4-4d89-cab5-a69dcc8012c3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: 32 symbols\n",
            "B: 14 symbols\n",
            "C: 48 symbols\n",
            "D: 10 symbols\n",
            "E: 10 symbols\n",
            "F: 2 symbols\n",
            "G: 4 symbols\n",
            "H: 25 symbols\n",
            "I: 1 symbols\n",
            "J: 7 symbols\n",
            "K: 11 symbols\n",
            "L: 27 symbols\n",
            "M: 15 symbols\n",
            "N: 7 symbols\n",
            "O: 4 symbols\n",
            "P: 11 symbols\n",
            "[Q] No symbols found. Top-level keys: ['reqAlphabetical']\n",
            "Q: 0 symbols\n",
            "R: 16 symbols\n",
            "S: 31 symbols\n",
            "T: 19 symbols\n",
            "U: 6 symbols\n",
            "V: 5 symbols\n",
            "W: 3 symbols\n",
            "[X] No symbols found. Top-level keys: ['reqAlphabetical']\n",
            "X: 0 symbols\n",
            "Y: 1 symbols\n",
            "[Z] No symbols found. Top-level keys: ['reqAlphabetical']\n",
            "Z: 0 symbols\n",
            "Total unique symbols: 309\n",
            "[1/309] AAF.N0000  \n",
            "[2/309] AAF.P0000  \n",
            "[3/309] AAIC.N0000  \n",
            "[4/309] ABAN.N0000  \n",
            "[5/309] ABL.N0000  \n",
            "[6/309] ACAP.N0000  \n",
            "[7/309] ACL.N0000  \n",
            "[8/309] ACME.N0000  \n",
            "[9/309] AEL.N0000  \n",
            "[10/309] AFS.N0000  \n",
            "[11/309] AFSL.N0000  \n",
            "[12/309] AGAL.N0000  \n",
            "[13/309] AGPL.N0000  \n",
            "[14/309] AGST.N0000  \n",
            "[15/309] AGST.X0000  \n",
            "[16/309] AHPL.N0000  \n",
            "[17/309] AHUN.N0000  \n",
            "[18/309] AINS.N0000  \n",
            "[19/309] ALHP.N0000  \n",
            "[20/309] ALLI.N0000  \n",
            "[21/309] ALUM.N0000  \n",
            "[22/309] AMCL.N0000  \n",
            "[23/309] AMF.N0000  \n",
            "[24/309] AMSL.N0000  \n",
            "[25/309] APLA.N0000  \n",
            "[26/309] ASCO.N0000  \n",
            "[27/309] ASHO.N0000  \n",
            "[28/309] ASIR.N0000  \n",
            "[29/309] ASIY.N0000  \n",
            "[30/309] ASPH.N0000  \n",
            "[31/309] ASPM.N0000  \n",
            "[32/309] ATL.N0000  \n",
            "[33/309] ATLL.N0000  \n",
            "[34/309] AUTO.N0000  \n",
            "[35/309] BALA.N0000  \n",
            "[36/309] BBH.N0000  \n",
            "[37/309] BERU.N0000  \n",
            "[38/309] BFL.N0000  \n",
            "[39/309] BFN.N0000  \n",
            "[40/309] BIL.N0000  \n",
            "[41/309] BLI.N0000  \n",
            "[42/309] BLUE.N0000  \n",
            "[43/309] BLUE.X0000  \n",
            "[44/309] BOGA.N0000  \n",
            "[45/309] BOPL.N0000  \n",
            "[46/309] BPPL.N0000  \n",
            "[47/309] BREW.N0000  \n",
            "[48/309] BRR.N0000  \n",
            "[49/309] BRWN.N0000  \n",
            "[50/309] BUKI.N0000  \n",
            "[51/309] CABO.N0000  \n",
            "[52/309] CALC.U0000  \n",
            "[53/309] CALF.N0000  \n",
            "[54/309] CALH.N0000  \n",
            "[55/309] CALI.U0000  \n",
            "[56/309] CALT.N0000  \n",
            "[57/309] CARE.N0000  \n",
            "[58/309] CARG.N0000  \n",
            "[59/309] CARS.N0000  \n",
            "[60/309] CBNK.N0000  \n",
            "[61/309] CCS.N0000  \n",
            "[62/309] CDB.N0000  \n",
            "[63/309] CDB.X0000  \n",
            "[64/309] CERA.N0000  \n",
            "[65/309] CFI.N0000  \n",
            "[66/309] CFIN.N0000  \n",
            "[67/309] CFLB.N0000  \n",
            "[68/309] CFVF.N0000  \n",
            "[69/309] CHL.N0000  \n",
            "[70/309] CHL.X0000  \n",
            "[71/309] CHMX.N0000  \n",
            "[72/309] CHOT.N0000  \n",
            "[73/309] CHOU.N0000  \n",
            "[74/309] CIC.N0000  \n",
            "[75/309] CIC.X0000  \n",
            "[76/309] CIND.N0000  \n",
            "[77/309] CINS.N0000  \n",
            "[78/309] CINS.X0000  \n",
            "[79/309] CINV.N0000  \n",
            "[80/309] CIT.N0000  \n",
            "[81/309] CITH.N0000  \n",
            "[82/309] CITW.N0000  \n",
            "[83/309] CLND.N0000  \n",
            "[84/309] COCO.N0000  \n",
            "[85/309] COCO.X0000  \n",
            "[86/309] COCR.N0000  \n",
            "[87/309] COF.U0000  \n",
            "[88/309] COLO.N0000  \n",
            "[89/309] COMB.N0000  \n",
            "[90/309] COMB.X0000  \n",
            "[91/309] COMD.N0000  \n",
            "[92/309] CONN.N0000  \n",
            "[93/309] COOP.N0000  \n",
            "[94/309] CPRT.N0000  \n",
            "[95/309] CRL.N0000  \n",
            "[96/309] CSD.N0000  \n",
            "[97/309] CSF.N0000  \n",
            "[98/309] CSLK.N0000  \n",
            "[99/309] CTBL.N0000  \n",
            "[100/309] CTC.N0000  \n",
            "[101/309] CTEA.N0000  \n",
            "[102/309] CTHR.N0000  \n",
            "[103/309] CTLD.N0000  \n",
            "[104/309] CWL.N0000  \n",
            "[105/309] CWM.N0000  \n",
            "[106/309] DFCC.N0000  \n",
            "[107/309] DIAL.N0000  \n",
            "[108/309] DIMO.N0000  \n",
            "[109/309] DIPD.N0000  \n",
            "[110/309] DIST.N0000  \n",
            "[111/309] DOCK.N0000  \n",
            "[112/309] DPL.N0000  \n",
            "[113/309] EAST.N0000  \n",
            "[114/309] EBCR.N0000  \n",
            "[115/309] ECL.N0000  \n",
            "[116/309] EDEN.N0000  \n",
            "[117/309] ELPL.N0000  \n",
            "[118/309] EMER.N0000  \n",
            "[119/309] EML.N0000  \n",
            "[120/309] ETWO.N0000  \n",
            "[121/309] EXT.N0000  \n",
            "[122/309] FCT.N0000  \n",
            "[123/309] GEST.N0000  \n",
            "[124/309] GHLL.N0000  \n",
            "[125/309] GLAS.N0000  \n",
            "[126/309] GRAN.N0000  \n",
            "[127/309] GREG.N0000  \n",
            "[128/309] GUAR.N0000  \n",
            "[129/309] HAPU.N0000  \n",
            "[130/309] HARI.N0000  \n",
            "[131/309] HASU.N0000  \n",
            "[132/309] HAYC.N0000  \n",
            "[133/309] HAYL.N0000  \n",
            "[134/309] HBS.N0000  \n",
            "[135/309] HDFC.N0000  \n",
            "[136/309] HELA.N0000  \n",
            "[137/309] HEXP.N0000  \n",
            "[138/309] HHL.N0000  \n",
            "[139/309] HNB.N0000  \n",
            "[140/309] HNB.X0000  \n",
            "[141/309] HNBF.N0000  \n",
            "[142/309] HNBF.R0000  \n",
            "[143/309] HNBF.R0001  \n",
            "[144/309] HNBF.X0000  \n",
            "[145/309] HOPL.N0000  \n",
            "[146/309] HPFL.N0000  \n",
            "[147/309] HPL.N0000  \n",
            "[148/309] HPWR.N0000  \n",
            "[149/309] HSIG.N0000  \n",
            "[150/309] HUNA.N0000  \n",
            "[151/309] HUNT.N0000  \n",
            "[152/309] HVA.N0000  \n",
            "[153/309] IDL.N0000  \n",
            "[154/309] JAT.N0000  \n",
            "[155/309] JETS.N0000  \n",
            "[156/309] JINS.N0000  \n",
            "[157/309] JKH.N0000  \n",
            "[158/309] JKL.N0000  \n",
            "[159/309] KAHA.N0000  \n",
            "[160/309] KCAB.N0000  \n",
            "[161/309] KDL.N0000  \n",
            "[162/309] KFP.N0000  \n",
            "[163/309] KGAL.N0000  \n",
            "[164/309] KHC.N0000  \n",
            "[165/309] KHL.N0000  \n",
            "[166/309] KOTA.N0000  \n",
            "[167/309] KPHL.N0000  \n",
            "[168/309] KVAL.N0000  \n",
            "[169/309] KZOO.N0000  \n",
            "[170/309] LALU.N0000  \n",
            "[171/309] LAMB.N0000  \n",
            "[172/309] LCBF.N0000  \n",
            "[173/309] LCEY.N0000  \n",
            "[174/309] LDEV.N0000  \n",
            "[175/309] LFIN.N0000  \n",
            "[176/309] LGIL.N0000  \n",
            "[177/309] LGL.N0000  \n",
            "[178/309] LGL.X0000  \n",
            "[179/309] LHCL.N0000  \n",
            "[180/309] LHL.N0000  \n",
            "[181/309] LIOC.N0000  \n",
            "[182/309] LION.N0000  \n",
            "[183/309] LITE.N0000  \n",
            "[184/309] LLUB.N0000  \n",
            "[185/309] LMF.N0000  \n",
            "[186/309] LOFC.N0000  \n",
            "[187/309] LOLC.N0000  \n",
            "[188/309] LPL.N0000  \n",
            "[189/309] LPL.X0000  \n",
            "[190/309] LPRT.N0000  \n",
            "[191/309] LUMX.N0000  \n",
            "[192/309] LVEF.N0000  \n",
            "[193/309] LVEN.N0000  \n",
            "[194/309] LWL.N0000  \n",
            "[195/309] MADU.N0000  \n",
            "[196/309] MAL.N0000  \n",
            "[197/309] MAL.X0000  \n",
            "[198/309] MARA.N0000  \n",
            "[199/309] MASK.N0000  \n",
            "[200/309] MBSL.N0000  \n",
            "[201/309] MCPL.N0000  \n",
            "[202/309] MDL.N0000  \n",
            "[203/309] MEL.N0000  \n",
            "[204/309] MELS.N0000  \n",
            "[205/309] MERC.N0000  \n",
            "[206/309] MFPE.N0000  \n",
            "[207/309] MGT.N0000  \n",
            "[208/309] MHDL.N0000  \n",
            "[209/309] MRH.N0000  \n",
            "[210/309] MSL.N0000  \n",
            "[211/309] MULL.N0000  \n",
            "[212/309] NAMU.N0000  \n",
            "[213/309] NAVF.U0000  \n",
            "[214/309] NDB.N0000  \n",
            "[215/309] NEH.N0000  \n",
            "[216/309] NHL.N0000  \n",
            "[217/309] NTB.N0000  \n",
            "[218/309] NTB.X0000  \n",
            "[219/309] ODEL.N0000  \n",
            "[220/309] OFEQ.N0000  \n",
            "[221/309] ONAL.N0000  \n",
            "[222/309] OSEA.N0000  \n",
            "[223/309] PABC.N0000  \n",
            "[224/309] PACK.N0000  \n",
            "[225/309] PALM.N0000  \n",
            "[226/309] PAP.N0000  \n",
            "[227/309] PARA.N0000  \n",
            "[228/309] PARQ.N0000  \n",
            "[229/309] PEG.N0000  \n",
            "[230/309] PHAR.N0000  \n",
            "[231/309] PINS.N0000  \n",
            "[232/309] PKME.N0000  \n",
            "[233/309] PLC.N0000  \n",
            "[234/309] PLR.N0000  \n",
            "[235/309] PMB.N0000  \n",
            "[236/309] RAL.N0000  \n",
            "[237/309] RCH.N0000  \n",
            "[238/309] RCL.N0000  \n",
            "[239/309] REEF.N0000  \n",
            "[240/309] RENU.N0000  \n",
            "[241/309] REXP.N0000  \n",
            "[242/309] RFL.N0000  \n",
            "[243/309] RGEM.N0000  \n",
            "[244/309] RHL.N0000  \n",
            "[245/309] RHL.X0000  \n",
            "[246/309] RHTL.N0000  \n",
            "[247/309] RICH.N0000  \n",
            "[248/309] RIL.N0000  \n",
            "[249/309] RPBH.N0000  \n",
            "[250/309] RWSL.N0000  \n",
            "[251/309] SAMP.N0000  \n",
            "[252/309] SCAP.N0000  \n",
            "[253/309] SDB.N0000  \n",
            "[254/309] SDF.N0000  \n",
            "[255/309] SEMB.N0000  \n",
            "[256/309] SEMB.X0000  \n",
            "[257/309] SERV.N0000  \n",
            "[258/309] SEYB.N0000  \n",
            "[259/309] SEYB.X0000  \n",
            "[260/309] SFCL.N0000  \n",
            "[261/309] SFIN.N0000  \n",
            "[262/309] SHAW.N0000  \n",
            "[263/309] SHL.N0000  \n",
            "[264/309] SHL.W0000  \n",
            "[265/309] SHOT.N0000  \n",
            "[266/309] SHOT.X0000  \n",
            "[267/309] SIGV.N0000  \n",
            "[268/309] SIL.N0000  \n",
            "[269/309] SING.N0000  \n",
            "[270/309] SINH.N0000  \n",
            "[271/309] SINS.N0000  \n",
            "[272/309] SIRA.N0000  \n",
            "[273/309] SLND.N0000  \n",
            "[274/309] SLTL.N0000  \n",
            "[275/309] SMOT.N0000  \n",
            "[276/309] SOY.N0000  \n",
            "[277/309] SPEN.N0000  \n",
            "[278/309] STAF.N0000  \n",
            "[279/309] SUN.N0000  \n",
            "[280/309] SWAD.N0000  \n",
            "[281/309] TAFL.N0000  \n",
            "[282/309] TAJ.N0000  \n",
            "[283/309] TANG.N0000  \n",
            "[284/309] TAP.N0000  \n",
            "[285/309] TESS.N0000  \n",
            "[286/309] TESS.X0000  \n",
            "[287/309] TILE.N0000  \n",
            "[288/309] TJL.N0000  \n",
            "[289/309] TKYO.N0000  \n",
            "[290/309] TKYO.X0000  \n",
            "[291/309] TPL.N0000  \n",
            "[292/309] TRAN.N0000  \n",
            "[293/309] TSML.N0000  \n",
            "[294/309] TYRE.N0000  \n",
            "[295/309] UAL.N0000  \n",
            "[296/309] UBC.N0000  \n",
            "[297/309] UBF.N0000  \n",
            "[298/309] UCAR.N0000  \n",
            "[299/309] UDPL.N0000  \n",
            "[300/309] UML.N0000  \n",
            "[301/309] VFIN.N0000  \n",
            "[302/309] VLL.N0000  \n",
            "[303/309] VLL.X0000  \n",
            "[304/309] VONE.N0000  \n",
            "[305/309] VPEL.N0000  \n",
            "[306/309] WAPO.N0000  \n",
            "[307/309] WATA.N0000  \n",
            "[308/309] WIND.N0000  \n",
            "[309/309] YORK.N0000  \n",
            "âœ… Wrote 309 rows â†’ cse_company_info_20250903_045906.csv\n",
            "âœ… Also wrote Excel file â†’ cse_company_info_20250903_045906.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, time, csv, json, ast\n",
        "from datetime import datetime\n",
        "\n",
        "BASE = \"https://www.cse.lk/api/\"\n",
        "CSV_OUT = f\"cse_company_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "LETTERS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "\n",
        "SESSION = requests.Session()\n",
        "SESSION.headers.update({\n",
        "    \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
        "    \"User-Agent\": \"Mozilla/5.0\",\n",
        "    \"Origin\": \"https://www.cse.lk\",\n",
        "    \"Referer\": \"https://www.cse.lk/\",\n",
        "})\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Helpers for extracting nested or stringified JSON blocks\n",
        "# -------------------------------------------------------------------\n",
        "TARGET_HINTS = {\n",
        "    \"name\",\"companyName\",\"Name\",\n",
        "    \"lastTradedPrice\",\"closingPrice\",\"previousClose\",\n",
        "    \"tdyTurnover\",\"turnover\",\n",
        "    \"tdyShareVolume\",\"shareVolume\",\n",
        "    \"tdyTradeVolume\",\"tradeVolume\",\n",
        "    \"hiTrade\",\"lowTrade\",\n",
        "    \"marketCap\",\"marketCapitalization\",\"marketCapPercentage\",\n",
        "    \"betaValueAspi\",\"betaValuesAspi\",\"betaAspi\",\n",
        "    \"betaValueSL20\",\"betaValuesSL20\",\"betaSl20\",\n",
        "    \"isin\",\"symbol\"\n",
        "}\n",
        "\n",
        "def try_parse_maybe_json(x):\n",
        "    \"\"\"If a value is a string that looks like JSON or a Python dict, parse it.\"\"\"\n",
        "    if not isinstance(x, str):\n",
        "        return x\n",
        "    s = x.strip()\n",
        "    if not s:\n",
        "        return x\n",
        "    # JSON-style\n",
        "    if (s.startswith(\"{\") and s.endswith(\"}\")) or (s.startswith(\"[\") and s.endswith(\"]\")):\n",
        "        try:\n",
        "            return json.loads(s)\n",
        "        except Exception:\n",
        "            pass\n",
        "    # Python literal-style (what we saw in your earlier CSV)\n",
        "    try:\n",
        "        return ast.literal_eval(s)\n",
        "    except Exception:\n",
        "        return x\n",
        "\n",
        "def deep_find_detail_block(obj):\n",
        "    \"\"\"\n",
        "    Walk the structure, return the FIRST dict that contains our target keys.\n",
        "    Auto-parses stringified dicts along the way.\n",
        "    \"\"\"\n",
        "    obj = try_parse_maybe_json(obj)\n",
        "\n",
        "    if isinstance(obj, dict):\n",
        "        if any(k in obj for k in TARGET_HINTS):\n",
        "            return obj\n",
        "        for v in obj.values():\n",
        "            found = deep_find_detail_block(v)\n",
        "            if isinstance(found, dict):\n",
        "                return found\n",
        "\n",
        "    elif isinstance(obj, list):\n",
        "        for it in obj:\n",
        "            found = deep_find_detail_block(it)\n",
        "            if isinstance(found, dict):\n",
        "                return found\n",
        "\n",
        "    return None\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# API calls\n",
        "# -------------------------------------------------------------------\n",
        "def extract_symbols(payload):\n",
        "    \"\"\"Get symbols from /alphabetical response.\"\"\"\n",
        "    out = set()\n",
        "    if isinstance(payload, list):\n",
        "        for it in payload:\n",
        "            if isinstance(it, dict) and \"symbol\" in it:\n",
        "                out.add(it[\"symbol\"])\n",
        "            elif isinstance(it, str):\n",
        "                out.add(it)\n",
        "    elif isinstance(payload, dict):\n",
        "        for v in payload.values():\n",
        "            if isinstance(v, list):\n",
        "                for it in v:\n",
        "                    if isinstance(it, dict) and \"symbol\" in it:\n",
        "                        out.add(it[\"symbol\"])\n",
        "    return sorted(out)\n",
        "\n",
        "def get_symbols(letter):\n",
        "    r = SESSION.post(BASE + \"alphabetical\", data={\"alphabet\": letter})\n",
        "    if r.status_code != 200:\n",
        "        print(f\"[{letter}] HTTP {r.status_code}\")\n",
        "        return []\n",
        "    try:\n",
        "        data = r.json()\n",
        "    except Exception:\n",
        "        print(f\"[{letter}] JSON parse error\")\n",
        "        return []\n",
        "    syms = extract_symbols(data)\n",
        "    print(f\"{letter}: {len(syms)} symbols\")\n",
        "    return syms\n",
        "\n",
        "def get_company_summary(symbol):\n",
        "    r = SESSION.post(BASE + \"companyInfoSummery\", data={\"symbol\": symbol})\n",
        "    if r.status_code != 200:\n",
        "        print(f\"{symbol}: HTTP {r.status_code}\")\n",
        "        return None\n",
        "    try:\n",
        "        payload = r.json()\n",
        "    except Exception:\n",
        "        print(f\"{symbol}: JSON parse error\")\n",
        "        return None\n",
        "\n",
        "    # Dive into nested or stringified structures\n",
        "    data = deep_find_detail_block(payload) or (payload if isinstance(payload, dict) else None)\n",
        "    if not isinstance(data, dict):\n",
        "        return {\"symbol\": symbol}\n",
        "\n",
        "    # unify name\n",
        "    name = data.get(\"name\") or data.get(\"companyName\") or data.get(\"Name\")\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"symbol\": data.get(\"symbol\", symbol),\n",
        "        \"isin\": data.get(\"isin\"),\n",
        "\n",
        "        \"lastTradedPrice\": data.get(\"lastTradedPrice\"),\n",
        "        \"previousClose\": data.get(\"previousClose\"),\n",
        "\n",
        "        \"turnover\": data.get(\"tdyTurnover\") or data.get(\"turnover\"),\n",
        "        \"shareVolume\": data.get(\"tdyShareVolume\") or data.get(\"shareVolume\"),\n",
        "        \"tradeVolume\": data.get(\"tdyTradeVolume\") or data.get(\"tradeVolume\"),\n",
        "\n",
        "        \"dayHigh\": data.get(\"hiTrade\"),\n",
        "        \"dayLow\": data.get(\"lowTrade\"),\n",
        "\n",
        "        \"marketCap\": data.get(\"marketCap\") or data.get(\"marketCapitalization\"),\n",
        "        \"marketCapPercentage\": data.get(\"marketCapPercentage\"),\n",
        "    }\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Main\n",
        "# -------------------------------------------------------------------\n",
        "def main():\n",
        "    # 1) Gather all symbols Aâ€“Z\n",
        "    symbols = []\n",
        "    for L in LETTERS:\n",
        "        symbols.extend(get_symbols(L))\n",
        "    symbols = sorted(set(symbols))\n",
        "    print(f\"âœ… Total symbols found: {len(symbols)}\")\n",
        "\n",
        "    # 2) Fetch summaries\n",
        "    rows = []\n",
        "    for i, sym in enumerate(symbols, 1):\n",
        "        info = get_company_summary(sym)\n",
        "        if info:\n",
        "            rows.append(info)\n",
        "        if i % 20 == 0:\n",
        "            print(f\"   â€¦fetched {i}/{len(symbols)}\")\n",
        "\n",
        "    if not rows:\n",
        "        print(\"âŒ No data fetched.\")\n",
        "        return\n",
        "\n",
        "    # 3) Save to CSV\n",
        "    cols = [\"name\",\"symbol\",\"isin\",\"lastTradedPrice\",\"previousClose\",\n",
        "            \"turnover\",\"shareVolume\",\"tradeVolume\",\"dayHigh\",\"dayLow\",\n",
        "            \"marketCap\",\"marketCapPercentage\"]\n",
        "\n",
        "    with open(CSV_OUT, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=cols)\n",
        "        w.writeheader()\n",
        "        w.writerows(rows)\n",
        "\n",
        "    print(f\"ðŸŽ‰ Done! Wrote {len(rows)} rows â†’ {CSV_OUT}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-DZ-UnUCWh5",
        "outputId": "bae89175-2ad9-44eb-b1d2-2f1bb366e9e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: 32 symbols\n",
            "B: 14 symbols\n",
            "C: 48 symbols\n",
            "D: 10 symbols\n",
            "E: 10 symbols\n",
            "F: 2 symbols\n",
            "G: 4 symbols\n",
            "H: 25 symbols\n",
            "I: 1 symbols\n",
            "J: 7 symbols\n",
            "K: 11 symbols\n",
            "L: 27 symbols\n",
            "M: 15 symbols\n",
            "N: 7 symbols\n",
            "O: 4 symbols\n",
            "P: 11 symbols\n",
            "Q: 0 symbols\n",
            "R: 16 symbols\n",
            "S: 31 symbols\n",
            "T: 19 symbols\n",
            "U: 6 symbols\n",
            "V: 5 symbols\n",
            "W: 3 symbols\n",
            "X: 0 symbols\n",
            "Y: 1 symbols\n",
            "Z: 0 symbols\n",
            "âœ… Total symbols found: 309\n",
            "   â€¦fetched 20/309\n",
            "   â€¦fetched 40/309\n",
            "   â€¦fetched 60/309\n",
            "   â€¦fetched 80/309\n",
            "   â€¦fetched 100/309\n",
            "   â€¦fetched 120/309\n",
            "   â€¦fetched 140/309\n",
            "   â€¦fetched 160/309\n",
            "   â€¦fetched 180/309\n",
            "   â€¦fetched 200/309\n",
            "   â€¦fetched 220/309\n",
            "   â€¦fetched 240/309\n",
            "   â€¦fetched 260/309\n",
            "   â€¦fetched 280/309\n",
            "   â€¦fetched 300/309\n",
            "ðŸŽ‰ Done! Wrote 309 rows â†’ cse_company_summary_20250904_034334.csv\n"
          ]
        }
      ]
    }
  ]
}